{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mbrudd/LLMs/blob/main/trainable_attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c33a1a1",
      "metadata": {
        "id": "7c33a1a1"
      },
      "source": [
        "# Attention with trainable weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c78b079a",
      "metadata": {
        "id": "c78b079a"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "d1c0c81b",
      "metadata": {
        "id": "d1c0c81b"
      },
      "outputs": [],
      "source": [
        "inputs = torch.nn.Embedding( 4, 8 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "oNX4cULRxBVk",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNX4cULRxBVk",
        "outputId": "9249d2f9-202a-44f4-a093-7d54bfa39e47"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-1.3292,  0.8097, -0.5553,  0.6602,  0.7835, -0.8741, -0.1003,  0.2274],\n",
              "        [ 1.5720, -0.8101,  1.1156,  0.1344, -0.0241, -1.1807,  0.1780,  0.6366],\n",
              "        [-1.3231,  1.6145,  0.9073, -1.0970, -1.6432,  0.4971, -0.7370,  1.1564],\n",
              "        [ 0.0386, -0.1957,  0.2020,  0.6749, -1.2907,  1.2601,  1.8761, -0.9480]],\n",
              "       requires_grad=True)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inputs = inputs.weight\n",
        "inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "sTBV2KZYxCLY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTBV2KZYxCLY",
        "outputId": "242227a8-6605-4437-da34-4afd884ba690"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-1.3292,  0.8097, -0.5553,  0.6602,  0.7835, -0.8741, -0.1003,  0.2274],\n",
              "        [ 1.5720, -0.8101,  1.1156,  0.1344, -0.0241, -1.1807,  0.1780,  0.6366],\n",
              "        [-1.3231,  1.6145,  0.9073, -1.0970, -1.6432,  0.4971, -0.7370,  1.1564],\n",
              "        [ 0.0386, -0.1957,  0.2020,  0.6749, -1.2907,  1.2601,  1.8761, -0.9480]])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inputs = inputs.data\n",
        "inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "QOwlthXbxb38",
      "metadata": {
        "id": "QOwlthXbxb38"
      },
      "outputs": [],
      "source": [
        "# set dimensions\n",
        "d_in = 8\n",
        "d_out = 6\n",
        "\n",
        "# create weight matrices\n",
        "W_q = torch.nn.Parameter( torch.rand( d_in, d_out ), requires_grad=False )\n",
        "W_k = torch.nn.Parameter( torch.rand( d_in, d_out ), requires_grad=False )\n",
        "W_v = torch.nn.Parameter( torch.rand( d_in, d_out ), requires_grad=False )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "sNXSVRxtyUEq",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNXSVRxtyUEq",
        "outputId": "bca25864-d5e0-4311-cc06-b6f02a41cf95"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([-0.1789,  0.2137,  0.0313, -0.7703, -0.1273, -1.8762])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# choose an input vector and transform it into our query vector using W_q\n",
        "query = inputs[2] @ W_q\n",
        "query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "krMfHBPty33R",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krMfHBPty33R",
        "outputId": "bcd09471-30db-4385-fc10-a8ca3bf2d2ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Keys: tensor([[-0.0394, -0.1689,  0.1785, -0.2056, -0.2069,  0.1211],\n",
            "        [ 1.5428,  0.8306, -0.4155,  1.2433,  1.0049,  1.8840],\n",
            "        [-1.1328,  0.5651,  0.8740,  0.4499,  0.2791, -1.5555],\n",
            "        [ 0.5014,  0.9252,  0.8923,  0.9109,  2.3291,  0.9026]])\n",
            "Values: tensor([[-2.7887e-02,  1.2724e-01, -7.9464e-01, -9.2495e-01, -3.9008e-01,\n",
            "         -8.9389e-04],\n",
            "        [ 7.1025e-01, -1.2465e-01,  5.1470e-01,  1.9723e+00,  1.4213e+00,\n",
            "          1.1743e+00],\n",
            "        [ 8.6978e-01,  1.3091e+00, -8.4407e-01,  1.5862e-01, -5.7497e-01,\n",
            "         -1.9002e+00],\n",
            "        [-1.9215e-01,  1.9280e+00,  1.4745e+00,  9.7672e-01, -2.5122e-01,\n",
            "          8.9286e-01]])\n"
          ]
        }
      ],
      "source": [
        "# calculate attention scores using the keys generated by W_k:\n",
        "keys = inputs @ W_k\n",
        "values = inputs @ W_v\n",
        "print(\"Keys:\", keys)\n",
        "print(\"Values:\", values )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "ZCYUxgufzYJx",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCYUxgufzYJx",
        "outputId": "749e4b32-891b-4115-b952-517980eb2571"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([-0.0660, -4.7322,  2.8872, -2.5558])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "attention_scores = query @ keys.T\n",
        "attention_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "8E3nKiYMz-B3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8E3nKiYMz-B3",
        "outputId": "6932da14-8aa7-4ed0-b6f3-7219b0cb5972"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0.2062, 0.0307, 0.6885, 0.0746])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "attention_weights = torch.softmax( attention_scores / keys.shape[-1]**0.5, dim = -1 )\n",
        "attention_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "ivp5ajUU0hVX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivp5ajUU0hVX",
        "outputId": "0d1fbb39-2929-4394-8056-857c2d57c20f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(1.0000)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "attention_weights.sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "NDyjIXnw01bw",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDyjIXnw01bw",
        "outputId": "f086797c-ecbe-4227-ebf9-929cb698314b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 0.6005,  1.0676, -0.6192,  0.0519, -0.4514, -1.2058])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "context_vector = attention_weights @ values\n",
        "context_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "mDJu60I-08oe",
      "metadata": {
        "id": "mDJu60I-08oe"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "nCNgyvAjDqJx",
      "metadata": {
        "id": "nCNgyvAjDqJx"
      },
      "outputs": [],
      "source": [
        "# here's a first version of a SimpleAttention class:\n",
        "\n",
        "class SimpleAttention( nn.Module ):\n",
        "  def __init__(self, d_in, d_out):\n",
        "    super().__init__()\n",
        "    # create weight matrices:\n",
        "    self.W_q = nn.Parameter( torch.rand( d_in, d_out ), requires_grad=False )\n",
        "    self.W_k = nn.Parameter( torch.rand( d_in, d_out ), requires_grad=False )\n",
        "    self.W_v = nn.Parameter( torch.rand( d_in, d_out ), requires_grad=False )\n",
        "\n",
        "  # x = embedding vectors (inputs)\n",
        "  def forward( self, x ):\n",
        "    queries = x @ self.W_q\n",
        "    keys = x @ self.W_k\n",
        "    values = x @ self.W_v\n",
        "    scores = queries @ keys.T\n",
        "    weights = torch.softmax( scores / keys.shape[-1]**0.5, dim = -1 )\n",
        "    context = weights @ values\n",
        "    return context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "WGqfizBVGQ6H",
      "metadata": {
        "id": "WGqfizBVGQ6H"
      },
      "outputs": [],
      "source": [
        "# here's how to use this class:\n",
        "# instantiate an instance of it:\n",
        "simple = SimpleAttention( d_in = 8, d_out = 6 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "m8khSsLLGbPx",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8khSsLLGbPx",
        "outputId": "3a733015-1789-4852-9500-5266acd05710"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[0.6136, 0.6489, 0.9762, 0.5870, 0.1912, 0.2031],\n",
              "        [0.1286, 0.1703, 0.6864, 0.0121, 0.9506, 0.1873],\n",
              "        [0.2859, 0.7420, 0.6053, 0.5492, 0.3664, 0.4607],\n",
              "        [0.7348, 0.2177, 0.6334, 0.1087, 0.6322, 0.4288],\n",
              "        [0.8806, 0.1077, 0.4198, 0.0882, 0.6358, 0.5097],\n",
              "        [0.3633, 0.8876, 0.7995, 0.6740, 0.7711, 0.7196],\n",
              "        [0.3058, 0.5988, 0.4124, 0.4454, 0.4333, 0.3269],\n",
              "        [0.1312, 0.2132, 0.4207, 0.4083, 0.1324, 0.0147]])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "simple.W_v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "IDXEWBn2GhTu",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDXEWBn2GhTu",
        "outputId": "d3ed3420-3b08-472b-8d0a-f90c80717f53"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-0.5132, -0.5743, -0.3829, -0.5475,  0.4309, -0.2044],\n",
              "        [ 0.4843,  1.0827,  0.9863,  1.0070, -0.2096,  0.1649],\n",
              "        [-0.2072, -1.4447, -0.8565, -1.2619,  0.4990, -0.3463],\n",
              "        [ 0.6911,  0.9978,  1.0359,  1.0256, -0.4437,  0.0611]])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "context_vectors = simple( inputs )\n",
        "context_vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "j0J4KZOZGqfu",
      "metadata": {
        "id": "j0J4KZOZGqfu"
      },
      "outputs": [],
      "source": [
        "# here's a second version of a SimpleAttention class ;\n",
        "# it uses nn.Linear to do things more efficiently\n",
        "\n",
        "class SimpleAttention( nn.Module ):\n",
        "  def __init__(self, d_in, d_out):\n",
        "    super().__init__()\n",
        "    # create weight matrices:\n",
        "    self.W_q = nn.Linear( d_in, d_out, bias=False )\n",
        "    self.W_k = nn.Linear( d_in, d_out, bias=False )\n",
        "    self.W_v = nn.Linear( d_in, d_out, bias=False )\n",
        "\n",
        "  # x = embedding vectors (inputs)\n",
        "  def forward( self, x ):\n",
        "    queries = self.W_q( x )\n",
        "    keys = self.W_k( x )\n",
        "    values = self.W_v( x )\n",
        "    scores = queries @ keys.T\n",
        "    weights = torch.softmax( scores / keys.shape[-1]**0.5, dim = -1 )\n",
        "    context = weights @ values\n",
        "    return context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "Zki5jtLCI6Cu",
      "metadata": {
        "id": "Zki5jtLCI6Cu"
      },
      "outputs": [],
      "source": [
        "# here's how to use this class:\n",
        "# instantiate an instance of it:\n",
        "simple = SimpleAttention( d_in = 8, d_out = 6 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "k6LcTWL9I8te",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6LcTWL9I8te",
        "outputId": "51c48a71-00d3-4fd5-8366-d33d91fbce9a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.2260, -0.2203, -0.3082,  0.2058, -0.2902, -0.2902],\n",
              "        [ 0.1543, -0.3560, -0.0465,  0.2560,  0.0202, -0.1348],\n",
              "        [ 0.2918, -0.1410, -0.4976,  0.1799, -0.4853, -0.4039],\n",
              "        [ 0.0494, -0.1248, -0.0317,  0.3531,  0.0764, -0.0907]],\n",
              "       grad_fn=<MmBackward0>)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "context_vectors = simple( inputs )\n",
        "context_vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "oue7IwuyI_ON",
      "metadata": {
        "id": "oue7IwuyI_ON"
      },
      "outputs": [],
      "source": [
        "# the problem with this is that each context vector uses information from ALL of the embedding vectors\n",
        "# in practice, we should only use information about the preceding embedding vectors\n",
        "# to accomplish this, we'll implement causal attention AKA masked attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "L734IABHc89l",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L734IABHc89l",
        "outputId": "014b83f6-4941-437b-99d9-00178eaada18"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.2677, 0.2808, 0.2081, 0.2434],\n",
              "        [0.2211, 0.2239, 0.3033, 0.2518],\n",
              "        [0.2330, 0.2468, 0.1668, 0.3533],\n",
              "        [0.2251, 0.2072, 0.3832, 0.1845]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# this is a hack to get some example weights to work with!\n",
        "# weights = simple( inputs )\n",
        "weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "SiNiJA_tdnIr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SiNiJA_tdnIr",
        "outputId": "ebb2ca07-84b2-449a-e5be-1da43a3c045d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1., 1., 1., 1.], grad_fn=<SumBackward1>)"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# note that these have already been normalized:\n",
        "weights.sum( dim=-1 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "w8qwVBb3d5YE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8qwVBb3d5YE",
        "outputId": "e255f66a-f578-44d3-d083-f35ef9fcaa45"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0., 0.],\n",
              "        [1., 1., 0., 0.],\n",
              "        [1., 1., 1., 0.],\n",
              "        [1., 1., 1., 1.]])"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# masking method #1\n",
        "simple_mask = torch.tril( torch.ones( weights.shape[0], weights.shape[0] ) )\n",
        "simple_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "aPN1GiEdeWq_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPN1GiEdeWq_",
        "outputId": "1bb88a6b-f8df-453b-cfde-bd0fa4a23965"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.2677, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2211, 0.2239, 0.0000, 0.0000],\n",
              "        [0.2330, 0.2468, 0.1668, 0.0000],\n",
              "        [0.2251, 0.2072, 0.3832, 0.1845]], grad_fn=<MulBackward0>)"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "masked_weights = weights*simple_mask\n",
        "masked_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "N-Ifwx0EfJs9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-Ifwx0EfJs9",
        "outputId": "8d1660e6-1795-4d50-bdbb-446941e56241"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0.2677, 0.4450, 0.6467, 1.0000], grad_fn=<SumBackward1>)"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "masked_weights.sum( dim=-1 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "gbOrqXGSfbm2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbOrqXGSfbm2",
        "outputId": "5f2be06c-b438-462c-e47f-1e1053819819"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.2677],\n",
              "        [0.4450],\n",
              "        [0.6467],\n",
              "        [1.0000]], grad_fn=<SumBackward1>)"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# now, we need to normalize the masked_weights so that each row has sum 1\n",
        "row_sums = masked_weights.sum( dim=-1, keepdim=True)\n",
        "row_sums"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "ACdob5jyfi2P",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACdob5jyfi2P",
        "outputId": "3c01e5e4-8d77-4675-a931-44fcd9ef21e9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1., 1., 1., 1.], grad_fn=<SumBackward1>)"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "masked_weights = masked_weights / row_sums\n",
        "masked_weights.sum( dim=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "0_aQEYcQf4tB",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_aQEYcQf4tB",
        "outputId": "3bb3ac91-91bb-4b83-ea0d-02ab006b0447"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.4968, 0.5032, 0.0000, 0.0000],\n",
              "        [0.3603, 0.3817, 0.2579, 0.0000],\n",
              "        [0.2251, 0.2072, 0.3832, 0.1845]], grad_fn=<DivBackward0>)"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "masked_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "QxaUROkpgBmr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxaUROkpgBmr",
        "outputId": "049a2c83-17d5-4e71-8420-670b567de6ba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0., 1., 1., 1.],\n",
              "        [0., 0., 1., 1.],\n",
              "        [0., 0., 0., 1.],\n",
              "        [0., 0., 0., 0.]])"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# masking method #2\n",
        "mask = torch.triu( torch.ones(weights.shape[0], weights.shape[0]), diagonal = 1 )\n",
        "mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "9aAkggNUhUAs",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9aAkggNUhUAs",
        "outputId": "b8ca6124-e6cb-4494-b173-e0170f47683d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[False,  True,  True,  True],\n",
              "        [False, False,  True,  True],\n",
              "        [False, False, False,  True],\n",
              "        [False, False, False, False]])"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mask.bool()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "84ev4pTZhoLD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84ev4pTZhoLD",
        "outputId": "7f8738e6-55fe-47de-bc37-dc0048687050"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.2677, 0.2808, 0.2081, 0.2434],\n",
              "        [0.2211, 0.2239, 0.3033, 0.2518],\n",
              "        [0.2330, 0.2468, 0.1668, 0.3533],\n",
              "        [0.2251, 0.2072, 0.3832, 0.1845]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "7AW_dLvCgiA8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AW_dLvCgiA8",
        "outputId": "b7b2dd2f-e681-490c-958c-e1e5253d49d1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.2677,   -inf,   -inf,   -inf],\n",
              "        [0.2211, 0.2239,   -inf,   -inf],\n",
              "        [0.2330, 0.2468, 0.1668,   -inf],\n",
              "        [0.2251, 0.2072, 0.3832, 0.1845]], grad_fn=<MaskedFillBackward0>)"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "weights = weights.masked_fill( mask.bool(), -torch.inf )\n",
        "weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "mMquJ-g1hvuq",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMquJ-g1hvuq",
        "outputId": "2951bdce-2e5b-471c-e318-a5985aee09b1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.4993, 0.5007, 0.0000, 0.0000],\n",
              "        [0.3390, 0.3437, 0.3173, 0.0000],\n",
              "        [0.2431, 0.2388, 0.2847, 0.2334]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "masked_weights = torch.softmax( weights, dim=-1 )\n",
        "masked_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "v0Rl7yaikQwW",
      "metadata": {
        "id": "v0Rl7yaikQwW"
      },
      "outputs": [],
      "source": [
        "## Dropout\n",
        "# idea: randomly select some data to leave out to avoid overfitting\n",
        "dropout = nn.Dropout( 0.5 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "Js4JQ6b9lN1p",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Js4JQ6b9lN1p",
        "outputId": "de67e7a3-499b-4004-d79c-b8090eef81fe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 1.0014, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 0.6346, 0.0000],\n",
              "        [0.4862, 0.0000, 0.5694, 0.4668]], grad_fn=<MulBackward0>)"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dropout( masked_weights )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "lwzL1olBjA62",
      "metadata": {
        "id": "lwzL1olBjA62"
      },
      "outputs": [],
      "source": [
        "# we need to be able to give our LLM batches of input\n",
        "# for example:\n",
        "batches = torch.stack( (inputs, inputs), dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "F9pE07dKjkPS",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9pE07dKjkPS",
        "outputId": "8b27786c-6ee8-475f-c08f-4fa053aad381"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 4, 8])"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batches.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uP2PuQ5RiCM8",
      "metadata": {
        "id": "uP2PuQ5RiCM8"
      },
      "outputs": [],
      "source": [
        "# this class needs to handle batches of input!\n",
        "\n",
        "class CausalAttention( nn.Module ):\n",
        "  def __init__(self, d_in, d_out, context_length, dropout, qkv_bias=False):\n",
        "    super().__init__()\n",
        "    # create weight matrices:\n",
        "    self.W_q = nn.Linear( d_in, d_out, bias=False )\n",
        "    self.W_k = nn.Linear( d_in, d_out, bias=False )\n",
        "    self.W_v = nn.Linear( d_in, d_out, bias=False )\n",
        "    self.dropout = nn.Dropout( dropout )\n",
        "    self.register_buffer('mask', torch.triu( torch.ones(context_length, context_length), diagonal = 1 ))\n",
        "\n",
        "  # x = embedding vectors (inputs)\n",
        "  def forward( self, x ):\n",
        "    queries = self.W_q( x )\n",
        "    keys = self.W_k( x )\n",
        "    values = self.W_v( x )\n",
        "    scores = queries @ keys.T\n",
        "    weights = torch.softmax( scores / keys.shape[-1]**0.5, dim = -1 )\n",
        "    context = weights @ values\n",
        "    return context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "268729f8",
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'CausalAttention' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m causal = \u001b[43mCausalAttention\u001b[49m( d_in=\u001b[32m8\u001b[39m, d_out=\u001b[32m6\u001b[39m, context_length=\u001b[32m4\u001b[39m, dropout=\u001b[32m0\u001b[39m)\n\u001b[32m      3\u001b[39m W_q = nn.Linear( d_in, d_out, bias=\u001b[38;5;28;01mFalse\u001b[39;00m )\n\u001b[32m      4\u001b[39m W_k = nn.Linear( d_in, d_out, bias=\u001b[38;5;28;01mFalse\u001b[39;00m )\n",
            "\u001b[31mNameError\u001b[39m: name 'CausalAttention' is not defined"
          ]
        }
      ],
      "source": [
        "causal = CausalAttention( d_in=8, d_out=6, context_length=4, dropout=0)\n",
        "\n",
        "W_q = nn.Linear( d_in, d_out, bias=False )\n",
        "W_k = nn.Linear( d_in, d_out, bias=False )\n",
        "W_v = nn.Linear( d_in, d_out, bias=False )\n",
        "\n",
        "queries = W_q( batches )\n",
        "queries"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
